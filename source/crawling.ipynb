{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카카오헤어샵 염색모 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://hairshop.kakao.com/proxy/app/v5/hair-styles?page=1&pageSize=500&gender=FEMALE&category=COLOR'\n",
    "headers= {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36',\n",
    "    'referer': 'https://hairshop.kakao.com/search/style?category=COLOR&gender=FEMALE',\n",
    "    'cookie': 'webid=b65e4c70777e11ebae0c000af759d1a0; webid_ts=1614267167415; TIARA=.CVmMcDw3NrD3z-VLqHoGwiXoT3cAIE3c1jlU-ldMnbB76GEMUCFIAXcym.AQuoaqPkTYgv9LujcC5b_otEEltCiScncmyMYUAa.Y-wb24k0; _ga=GA1.2.279864581.1651731863; _kadu=abYrP9JHpHfxq52Y_1655206813096; _kahai=4e16fe34731e20999b1ffecb4f75202088828e33ba8e52e62afcc81a2842def9; ingress_session=d07474dce9c03b1bad6571d0c9793898e0b52ff7; _csrf=zpfk_NBFtCTEPjzpur-Mb1YB; _kawlt=o-3B8IJbD1H4FYhOktdrT1MePPzYwARYuoNzVmahlrrPt8wcSkn9Aw3OmX_0nvSLqcCf5CYOtfcCGCXYrISv1MFmV-qwrac-M9H63s9Ve8qG-Cr5bjjOZeOzJ6hHoZFM; _kawltea=1669089691; _karmt=TC9ran787ljjoXEgZ397CHwi9YJifh7CO9yldz6k59S251cNp-Eo0xbXM1kRC54X; _karmtea=1671616891; __T_=1; _gid=GA1.2.1391551100.1669014093; _fbp=fb.1.1669014095503.1129549787; _gcl_au=1.1.567937723.1669014096; wcs_bt=7c493e2e5acf60:1669034296; _T_ANO=T9T8obQa0C3wJr4EaOoBS3LwNDQeWAW2UtOnpGk4q7n4OQgmVA7IOa9Xs+icZHptpcp2qT83HyyS3TcmrJrGR/+44rORcw2jiGOMqWzNeIBBM1eTY+YQvAqFC7rljfQwmtvbgmY8ZwOMpjlizlb3PPeKC37CaThW5Q+0E6uDaWb7Kg64EdkIsl8DQJI1xsKqaGsjdVhnHxJhjSAe9waAxMyITSPcOJ3Ml1lBU9aMIzfuS5B0udSKObbGmySxeYVT5kasEKRHWA2hwlGh0zc330fIR048vO4NAYKCRpnmum8Ln4lBFK45n19RlFEK2X4aF0pWNsLWdED2UVrwPc2lbg=='\n",
    "}\n",
    "resp = requests.get(url, headers=headers)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = resp.json()\n",
    "total_count = result['totalCount']\n",
    "\n",
    "total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9000개 이후 막힘.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(range(1, 12)):\n",
    "\n",
    "    url = 'https://hairshop.kakao.com/proxy/app/v5/hair-styles?page={0}&pageSize=1000&gender=MALE&category=COLOR'.format(i)\n",
    "    headers= {\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36',\n",
    "        'referer': 'https://hairshop.kakao.com/search/style?category=COLOR&gender=FEMALE',\n",
    "        'cookie': 'webid=b65e4c70777e11ebae0c000af759d1a0; webid_ts=1614267167415; TIARA=.CVmMcDw3NrD3z-VLqHoGwiXoT3cAIE3c1jlU-ldMnbB76GEMUCFIAXcym.AQuoaqPkTYgv9LujcC5b_otEEltCiScncmyMYUAa.Y-wb24k0; _ga=GA1.2.279864581.1651731863; _kadu=abYrP9JHpHfxq52Y_1655206813096; _kahai=4e16fe34731e20999b1ffecb4f75202088828e33ba8e52e62afcc81a2842def9; ingress_session=d07474dce9c03b1bad6571d0c9793898e0b52ff7; _csrf=zpfk_NBFtCTEPjzpur-Mb1YB; _kawlt=o-3B8IJbD1H4FYhOktdrT1MePPzYwARYuoNzVmahlrrPt8wcSkn9Aw3OmX_0nvSLqcCf5CYOtfcCGCXYrISv1MFmV-qwrac-M9H63s9Ve8qG-Cr5bjjOZeOzJ6hHoZFM; _kawltea=1669089691; _karmt=TC9ran787ljjoXEgZ397CHwi9YJifh7CO9yldz6k59S251cNp-Eo0xbXM1kRC54X; _karmtea=1671616891; __T_=1; _gid=GA1.2.1391551100.1669014093; _fbp=fb.1.1669014095503.1129549787; _gcl_au=1.1.567937723.1669014096; wcs_bt=7c493e2e5acf60:1669034296; _T_ANO=T9T8obQa0C3wJr4EaOoBS3LwNDQeWAW2UtOnpGk4q7n4OQgmVA7IOa9Xs+icZHptpcp2qT83HyyS3TcmrJrGR/+44rORcw2jiGOMqWzNeIBBM1eTY+YQvAqFC7rljfQwmtvbgmY8ZwOMpjlizlb3PPeKC37CaThW5Q+0E6uDaWb7Kg64EdkIsl8DQJI1xsKqaGsjdVhnHxJhjSAe9waAxMyITSPcOJ3Ml1lBU9aMIzfuS5B0udSKObbGmySxeYVT5kasEKRHWA2hwlGh0zc330fIR048vO4NAYKCRpnmum8Ln4lBFK45n19RlFEK2X4aF0pWNsLWdED2UVrwPc2lbg=='\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "\n",
    "    result = resp.json()\n",
    "    print(result)\n",
    "    json_list = result['contents']\n",
    "    \n",
    "\n",
    "    for j in range(len(json_list)):\n",
    "        resp_img = requests.get(json_list[j]['originalPhotoUrl'])\n",
    "\n",
    "        img = resp_img.content\n",
    "\n",
    "        with open('color/{:03}_0_{:05}.jpg'.format(i, j), 'wb') as f:\n",
    "            f.write(img)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = 'chromedriver.exe'\n",
    "browser = webdriver.Chrome(binary)\n",
    "number = 1\n",
    "\n",
    "for i in range(1, 11):\n",
    "\n",
    "    browser.get(\"https://search.naver.com/search.naver?where=image&datetype=6&startdate=2022.{0:02}.22&enddate=2022.{1:02}.22&sm=tab_jum&query=\".format(i, i+1))\n",
    "    elem = browser.find_element(\"id\", \"nx_query\")\n",
    "    elem.send_keys(\"남자염색\") # 손상모, 손상모발, 끝이 갈라진 머리, 손상 머리, 손상된 머리, 개털머리\n",
    "    elem.submit()\n",
    "\n",
    "\n",
    "    for j in range(1200): # 5\n",
    "        browser.find_element(\"xpath\", \"//body\").send_keys(Keys.DOWN)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    params = []\n",
    "    imgList = soup.select(\"img._image._listImage\")\n",
    "    for im in imgList:\n",
    "        params.append(im[\"src\"])\n",
    "\n",
    "    for p in params:\n",
    "        urllib.request.urlretrieve(p,  'color/{0}_1_1_{1:05}.jpg'.format(i, number))\n",
    "        number = number + 1 \n",
    "\n",
    "\n",
    "\n",
    "    print('!!!!!!!!!!!!!!!!!!!!!!!!! ------- 3: {0}~{1}'.format(i, i+1))\n",
    "    time.sleep(5)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손상모 네이버 이미지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = 'chromedriver.exe'\n",
    "browser = webdriver.Chrome(binary)\n",
    "browser.get(\"https://search.naver.com/search.naver?where=image&sm=tab_jum&query=\")\n",
    "elem = browser.find_element(\"id\", \"nx_query\")\n",
    "elem.send_keys(\"손상모발\") # 손상모, 손상모발, 끝이 갈라진 머리\n",
    "elem.submit()\n",
    "\n",
    "number = 1\n",
    "for i in range(5): # 5\n",
    "    browser.find_element(\"xpath\", \"//body\").send_keys(Keys.END)\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    params = []\n",
    "    imgList = soup.select(\"img._image._listImage\")\n",
    "    for im in imgList:\n",
    "        params.append(im[\"src\"])\n",
    "\n",
    "    for p in params:\n",
    "        urllib.request.urlretrieve(p,  'damaged_hair/{:05}.jpg'.format(number))\n",
    "        number = number + 1\n",
    "\n",
    "\n",
    "time.sleep(10) \n",
    "\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_date = [i for i in range(1, 12)]\n",
    "\n",
    "binary = 'chromedriver.exe'\n",
    "browser = webdriver.Chrome(binary)\n",
    "number = 1\n",
    "\n",
    "# for i in range(1, 11):\n",
    "\n",
    "    # browser.get(\"https://search.naver.com/search.naver?where=image&datetype=6&startdate=2022.{0:02}.22&enddate=2022.{1:02}.22&sm=tab_jum&color=black&query=\".format(i, i+1))\n",
    "browser.get(\"https://search.naver.com/search.naver?where=image&sm=tab_jum&color=black&query=\")\n",
    "elem = browser.find_element(\"id\", \"nx_query\")\n",
    "elem.send_keys(\"남자 자연머리\") # 손상모, 손상모발, 끝이 갈라진 머리, 손상 머리, 손상된 머리, 개털머리\n",
    "elem.submit()\n",
    "\n",
    "\n",
    "for j in range(1200): # 5\n",
    "    browser.find_element(\"xpath\", \"//body\").send_keys(Keys.DOWN)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "params = []\n",
    "imgList = soup.select(\"img._image._listImage\")\n",
    "for im in imgList:\n",
    "    params.append(im[\"src\"])\n",
    "\n",
    "for p in params:\n",
    "    urllib.request.urlretrieve(p,  'natural/{0}_{1:05}.jpg'.format(2, number))\n",
    "    number = number + 1 \n",
    "\n",
    "\n",
    "\n",
    "print('!!!!!!!!!!!!!!!!!!!!!!!!! ------- 3: {0}~{1}'.format(i, i+1))\n",
    "time.sleep(0.2)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일명 정리하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# damanged_hair_total 에 있는 파일명 수정 damanged_1_{:05}\n",
    "\n",
    "dest_path = 'color/'\n",
    "dest_list = sorted(os.listdir(dest_path))\n",
    "for i in range(len(dest_list)):\n",
    "    os.rename(dest_path + dest_list[i], dest_path + '{:05}.jpg'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0}_{1:05}'.format(1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 이미지 크기 중 큰 값, 작은 값 뽑아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "folder_path = 'color/'\n",
    "list_width, list_height = [], []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    try:\n",
    "        img = cv2.imread(folder_path + file)\n",
    "        list_width.append(img.shape[0])\n",
    "        list_height.append(img.shape[1])\n",
    "    except AttributeError:\n",
    "        print(file, 'is NoneType...')\n",
    "        continue\n",
    "\n",
    "print('--------- color:')\n",
    "print('max width: ', max(list_width), ', min width: ', min(list_width))\n",
    "print('max height: ', max(list_height), ', min height: ', min(list_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'damaged/'\n",
    "list_width, list_height = [], []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    try:\n",
    "        img = cv2.imread(folder_path + file)\n",
    "        list_width.append(img.shape[0])\n",
    "        list_height.append(img.shape[1])\n",
    "    except AttributeError:\n",
    "        print(file, 'is NoneType...')\n",
    "        continue\n",
    "\n",
    "print('--------- damaged:')\n",
    "print('max width: ', max(list_width), ', min width: ', min(list_width))\n",
    "print('max height: ', max(list_height), ', min height: ', min(list_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install split-folders matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install tensorflow -y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 염색모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'damaged_lot': []}\n",
    "folder_path = 'damaged_lot/'\n",
    "dest_folder_path = 'resized_224_224'\n",
    "\n",
    "# 이미지와 라벨 리스트에 담기\n",
    "for filename in os.listdir(folder_path):\n",
    "    dataset['damaged_lot'].append(folder_path + filename)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['damaged_lot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, filenames in dataset.items():\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            img = cv2.imread(filename)\n",
    "\n",
    "            # 이미지의 x, y가 224이 넘을 경우 작게해주기\n",
    "            percent = 1\n",
    "            if(img.shape[1] > img.shape[0]) :       # 이미지의 가로가 세보다 크면 가로를 640으로 맞추고 세로를 비율에 맞춰서\n",
    "                percent = 224/img.shape[1]\n",
    "            else :\n",
    "                percent = 224/img.shape[0]\n",
    "\n",
    "            img = cv2.resize(img, dsize=(0, 0), fx=percent, fy=percent, interpolation=cv2.INTER_LINEAR)\n",
    "                    # 이미지 범위 지정\n",
    "            y,x,h,w = (0,0,img.shape[0], img.shape[1])\n",
    "\n",
    "            # 그림 주변에 검은색으로 칠하기\n",
    "            w_x = (224-(w-x))/2  # w_x = (224 - 그림)을 뺀 나머지 영역 크기 [ 그림나머지/2 [그림] 그림나머지/2 ]\n",
    "            h_y = (224-(h-y))/2\n",
    "\n",
    "            if(w_x < 0):         # 크기가 -면 0으로 지정.\n",
    "                w_x = 0\n",
    "            elif(h_y < 0):\n",
    "                h_y = 0\n",
    "\n",
    "            M = np.float32([[1,0,w_x], [0,1,h_y]])  #(2*3 이차원 행렬)\n",
    "            img_re = cv2.warpAffine(img, M, (224, 224)) #이동변환  \n",
    "        \n",
    "            # cv2.imwrite('{0}.jpg',image .format(file)) #파일저장\n",
    "            dest_file_name = '{2}/{0}/{1}'.format(label, filename.split(\"/\")[-1], dest_folder_path)\n",
    "            cv2.imwrite(dest_file_name, img_re)\n",
    "            print(dest_file_name, 'is Writed...')\n",
    "\n",
    "        except Exception:\n",
    "            print(filename, 'is ERROR...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, validation, test set 폴더로 나눠주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio('resized_224_224', output='dataset_224_224', seed=77, ratio=(0.6, 0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset_224_224/train'\n",
    "dataset = {}\n",
    "\n",
    "# 이미지와 라벨 리스트에 담기\n",
    "for label in os.listdir(folder_path):\n",
    "    sub_path = folder_path+'/'+label+'/'\n",
    "    if os.path.isdir(sub_path):\n",
    "        dataset[label] = []\n",
    "        for filename in os.listdir(sub_path):\n",
    "            dataset[label].append(sub_path+filename)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2index = {'color' : 0, 'damaged_little' : 1 , 'damaged_lot' : 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "\n",
    "for label, filenames in dataset.items():\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(filename) # img를 array 형태로 변경\n",
    "\n",
    "        x_train.append(image)\n",
    "        y_train.append(label2index[label]) # label을 index로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('int8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset_224_224/train_augmentation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in  os.listdir(folder_path):\n",
    "    label_path = folder_path + '/' + label + '/'\n",
    "    if os.path.isdir(label_path):\n",
    "        for filename in os.listdir(label_path): \n",
    "            filepath = label_path + filename\n",
    "\n",
    "            img = load_img(filepath)\n",
    "            # img 출력\n",
    "            # plt.imshow(img)\n",
    "            # break\n",
    "            x = img_to_array(img)\n",
    "            # x.shape 출력\n",
    "            # print(x.shape)\n",
    "            # break\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            i = 0\n",
    "            # flow : augmentation 함수\n",
    "            for batch in datagen.flow(x, batch_size=1,\n",
    "                                    save_to_dir=label_path, save_prefix=label, save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > 2:\n",
    "                    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = 'dataset_224_224/train'\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "# 이미지와 라벨 리스트에 담기\n",
    "for label in os.listdir(folder_path):\n",
    "\n",
    "    sub_path = folder_path+'/'+label+'/'\n",
    "    if os.path.isdir(sub_path):\n",
    "        dataset[label] = []\n",
    "\n",
    "        for filename in os.listdir(sub_path):\n",
    "            dataset[label].append(sub_path+filename)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2index = {'color' : 0, 'damaged_little' : 1 , 'damaged_lot' : 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "\n",
    "for label, filenames in dataset.items():\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(filename) # img를 array 형태로 변경\n",
    "\n",
    "        x_train.append(image)\n",
    "        y_train.append(label2index[label]) # label을 index로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load validataion data, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset_224_224/val'\n",
    "dataset = {}\n",
    "\n",
    "# 이미지와 라벨 리스트에 담기\n",
    "for label in os.listdir(folder_path):\n",
    "    sub_path = folder_path+'/'+label+'/'\n",
    "    dataset[label] = []\n",
    "    for filename in os.listdir(sub_path):\n",
    "        dataset[label].append(sub_path+filename)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = [], []\n",
    "\n",
    "for label, filenames in dataset.items():\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(filename) # img를 array 형태로 변경\n",
    "\n",
    "        x_val.append(image)\n",
    "        y_val.append(label2index[label]) # label을 index로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val= np.array(x_val), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.astype('int8') # 메모리 문제로 비실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset_224_224/test'\n",
    "dataset = {}\n",
    "\n",
    "# 이미지와 라벨 리스트에 담기\n",
    "for label in os.listdir(folder_path):\n",
    "    sub_path = folder_path+'/'+label+'/'\n",
    "    dataset[label] = []\n",
    "    for filename in os.listdir(sub_path):\n",
    "        dataset[label].append(sub_path+filename)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = [], []\n",
    "\n",
    "for label, filenames in dataset.items():\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(filename) # img를 array 형태로 변경\n",
    "\n",
    "        x_test.append(image)\n",
    "        y_test.append(label2index[label]) # label을 index로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype('int8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zero centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean(image):\n",
    "    # zero-centering\n",
    "    return np.mean(image, axis=0)\n",
    "\n",
    "zero_mean_img = zero_mean(x_train)\n",
    "\n",
    "zero_mean_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mean_img = zero_mean_img.astype('int8') # 메모리 문제로 int8로 변환(근사값으로 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train -= zero_mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val -= zero_mean_img\n",
    "x_test -= zero_mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset_224_224/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'x_train.pickle', 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "\n",
    "with open(folder_path+'y_train.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(folder_path+'x_val.pickle', 'wb') as f:\n",
    "    pickle.dump(x_val, f)\n",
    "\n",
    "with open(folder_path+'y_val.pickle', 'wb') as f:\n",
    "    pickle.dump(y_val, f)\n",
    "\n",
    "with open(folder_path+'x_test.pickle', 'wb') as f:\n",
    "    pickle.dump(x_test, f)\n",
    "\n",
    "with open(folder_path+'y_test.pickle', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'x_train_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "\n",
    "with open(folder_path+'y_train_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(folder_path+'x_val_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(x_val, f)\n",
    "\n",
    "with open(folder_path+'y_val_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(y_val, f)\n",
    "\n",
    "with open(folder_path+'x_test_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(x_test, f)\n",
    "\n",
    "with open(folder_path+'y_test_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset_224_224/not_augmentation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'x_train.pickle', 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "\n",
    "with open(folder_path+'y_train.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'x_train_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "\n",
    "with open(folder_path+'y_train_zero.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.imshow(cv2.imread('dataset_224_224/train/color/00003.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset_224_224/not_augmentation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'x_train.pickle', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'y_train.pickle', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'x_val.pickle', 'rb') as f:\n",
    "    x_val = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'y_val.pickle', 'rb') as f:\n",
    "    y_val = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'x_test.pickle', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'y_test.pickle', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'x_train_zero.pickle', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'y_train_zero.pickle', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'x_val_zero.pickle', 'rb') as f:\n",
    "    x_val = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'y_val_zero.pickle', 'rb') as f:\n",
    "    y_val = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'x_test_zero.pickle', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "\n",
    "with open(folder_path+'y_test_zero.pickle', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models #Tensorflow에 있는 Keras 함수들 호출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_images \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\n\u001b[1;32m      2\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m y_train\n\u001b[1;32m      3\u001b[0m val_images \u001b[38;5;241m=\u001b[39m x_val\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_images = x_train\n",
    "train_labels = y_train\n",
    "val_images = x_val\n",
    "val_labels = y_val\n",
    "test_images = x_test\n",
    "test_labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images, val_images, test_images = train_images / 255.0, val_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구축\n",
    "model = models.Sequential()\n",
    "## filtering layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "\n",
    "## classification layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /Users/jeonminjeong/opt/miniconda3/lib/python3.9/site-packages (0.20.1)\n",
      "Requirement already satisfied: pydot in /Users/jeonminjeong/opt/miniconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/jeonminjeong/opt/miniconda3/lib/python3.9/site-packages (from pydot) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_shapes.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습\n",
    "# model.fit(train_images, train_labels, epochs=3,validation_split=0.2,verbose=1)\n",
    "model.fit(train_images, train_labels, epochs=3,validation_data=(val_images, val_labels),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 검증\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('loss: ', test_loss, ', acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = x_train\n",
    "train_labels = y_train\n",
    "val_images = x_val\n",
    "val_labels = y_val\n",
    "test_images = x_test\n",
    "test_labels = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=True, input_shape = (224, 224 ,3), weights = 'imagenet')\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = 'accuracy')\n",
    "model.evaluate(test_images, test_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류기 부분만 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=False, input_shape = (224, 224 ,3), weights = 'imagenet')\n",
    "base_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(train_labels, 3)\n",
    "y_val = tf.keras.utils.to_categorical(val_labels, 3)\n",
    "y_test = tf.keras.utils.to_categorical(test_labels, 3)\n",
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.Sequential()없이 모델 구축하는 방법\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x= tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_crossentropy\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# 모델 fitting\n",
    "model.fit(train_images, y_train, epochs = 10, validation_data=(val_images, y_val), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 검증\n",
    "test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\n",
    "print('loss: ', test_loss, ', acc: ', test_acc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하위층 일부 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=False, input_shape = (224, 224 ,3), weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:-20]: \n",
    "  layer.trainable = False\t\t\t\t\n",
    "\n",
    "for layer in base_model.layers[-100:]:\t\n",
    "  print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False) # batchnorm 부분 update 방지\n",
    "\n",
    "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x= tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam( learning_rate= 0.0001),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, y_train, epochs = 3, validation_data=(val_images, y_val), batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 검증\n",
    "test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\n",
    "print('loss: ', test_loss, ', acc: ', test_acc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전부 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=False, input_shape = (224, 224 ,3), weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\t\t\t\t\n",
    "\n",
    "for layer in base_model.layers[:]:\t\n",
    "  print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "x = tf.keras.layers.Flatten(input_shape=model.output_shape[1:])(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x= tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam( learning_rate= 0.0001),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, y_train, epochs = 3, validation_data=(val_images, y_val), batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 검증\n",
    "test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\n",
    "print('loss: ', test_loss, ', acc: ', test_acc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet 분류기만 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "base_model = tf.keras.applications.InceptionResNetV2(include_top=False, input_shape = (224, 224 ,3), weights = 'imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(train_labels, 3)\n",
    "y_test = tf.keras.utils.to_categorical(test_labels, 3)\n",
    "y_train.shape, y_test.shape\n",
    "\n",
    "# model.Sequential()없이 모델 구축하는 방법\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x= tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# categorical_crossentropy\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# 모델 fitting\n",
    "model.fit(train_images, y_train, epochs = 5, validation_data=(test_images, y_test), batch_size=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = tf.keras.utils.to_categorical(val_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 검증\n",
    "test_loss, test_acc = model.evaluate(val_images, y_val, verbose=2)\n",
    "print('loss: ', test_loss, ', acc: ', test_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy  --upgrade\n",
    "!pip install pandas  --upgrade\n",
    "!pip install matplotlib  --upgrade\n",
    "!pip install scikit-learn  --upgrade\n",
    "!pip install scipy  --upgrade\n",
    "!pip install plotly  --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy -y\n",
    "!conda install -c conda-forge numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c apple tensorflow-deps -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-12.3.1-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.10.0\n",
      "Keras Version: 2.10.0\n",
      "\n",
      "Python 3.9.12 (main, Apr  5 2022, 01:52:34) \n",
      "[Clang 12.0.0 ]\n",
      "Pandas 1.5.2\n",
      "SciPy 1.9.3\n",
      "True\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "# import sklearn as sk\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "# print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(f\"SciPy {sp.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(gpu)\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 16:13:47.854305: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-28 16:13:47.855331: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-11-28 16:13:47.958405: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2022-11-28 16:13:47.958437: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:47.958448: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:48.004642: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:48.004676: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:48.004689: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "RandomStandardNormal: (RandomStandardNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 16:13:48.205898: I tensorflow/core/common_runtime/placer.cc:114] shape: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2022-11-28 16:13:48.205947: I tensorflow/core/common_runtime/placer.cc:114] RandomStandardNormal: (RandomStandardNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:48.205957: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 16:13:49.579418: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:49.579461: I tensorflow/core/common_runtime/placer.cc:114] y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:49.579472: I tensorflow/core/common_runtime/placer.cc:114] Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:49.579479: I tensorflow/core/common_runtime/placer.cc:114] z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "AddV2: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 16:13:49.974727: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:49.974750: I tensorflow/core/common_runtime/placer.cc:114] y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:49.974762: I tensorflow/core/common_runtime/placer.cc:114] AddV2: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2022-11-28 16:13:49.974769: I tensorflow/core/common_runtime/placer.cc:114] z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(devices)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "a=tf.random.normal([100,100])\n",
    "b=tf.random.normal([100,100])\n",
    "c = a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger tensorflow (ERROR)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.get_logger()#setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.keras.utils.disable_interactive_logging()\n",
    "tf.autograph.set_verbosity(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"0\"\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6fd52d75628275c7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6fd52d75628275c7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd66a3275e96aee4b4cb96c25af671870044333669e75ee46a630b0d04b108e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
